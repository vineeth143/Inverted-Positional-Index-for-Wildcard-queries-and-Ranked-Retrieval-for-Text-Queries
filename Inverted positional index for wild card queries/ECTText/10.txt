intel corporation (nasdaq:intc) evercore isi virtual new mobility & ai forum conference call september 21, 2020 10:45 am et
executives
erez dagan - executive vice president, products and strategy, mobileye
tony balow - senior director and ir
analysts
c.j. muse - evercore isi
chris mcnally - evercore isi
c.j. muse
well, good morning and good afternoon, everyone. this is c.j. muse with evercore isi. it is my pleasure to welcome intel, and particularly, erez dagan, evp of products and strategy at mobileye; and tony balow, senior director and investor relations at intel.
intel and mobileye last offered a detailed look at its strategy for adas, autonomous vehicles at its analyst day in jerusalem back in november 2019. we know they have made great progress since then. so we are very eager to hear from the team.
erez will make a few opening comments, and then my colleague, chris mcnally and i will host the fireside chat. if you have any questions, there’s a box, you can send them to us. i will be sure to ask them on your behalf.
and with that, let me turn it over to erez.
erez dagan
hi. good morning. erez dagan, evp, products and strategy at mobileye. i am excited to chat with you here today. thanks a lot for the invitation. i suggest we go to the q&a.
question-and-answer session
q - c.j. muse
okay. excellent. so, i guess, i have been tasked with starting at a very high level, last november you outlined a strategy with clear focus on l2++, as well as robotaxi, as well as longer term focus on the passenger car autonomy side. so i would love to just hear, what has changed, what have you been able to accomplish in your overall strategy in the last kind of 10-plus months since we have heard from you?
erez dagan
perfect. so strategy is in place. we still see this -- first of all, in the driver assistance space, we see the separation between level 0 to level 2 as one segment. that’s driven by certain factors. there’s level 2+ segment, and there is the mobility-as-a-service or the robotaxi deployment arena for autonomy, robotaxi as the deployment arena of autonomy, followed by introduction of autonomy into the consumer market.
so in the driver assistance, we see lower end, we see the level 2+ segment. in the autonomy, we see the robotaxi is the primary production market and the consumer autonomy to be followed. within the mobility-as-a-service segment, the introduction of robotaxi -- autonomy for robotaxi, we have also through the past 10 months, as you probably well know, acquired moovit, acquired the company to complete the value chain -- the value loads that we required in order to launch a standalone mobility as a service.
and we also shared that we will have vehicle-as-a-service and rides-as-a-service as two derivative models. these two derivative models would allow us to interact and collaborate with public transit authorities on one hand through the vehicle-as-a-service model and ride-as-a-service and mostly designated to tncs, which don’t know how to operate the capital required for automated mobility solutions and can simply purchase rides under their own demand umbrella. this is kind of the high level of where we stand on strategic growth.
c.j. muse
that’s great. i guess, as a follow-up and really to help kind of think strategically about how you are attacking autonomous vehicles versus others, can you quickly describe your approach as it relates to using vision first and full true modality redundancy versus more traditional lidar-based simultaneous location and mapping, or perhaps, unique driving policy framework like rss versus end-to-end driving policy?
erez dagan
so it also has to do with previous question in the sense that we -- in our robotaxi approach, we separate the computer vision subsystem to be a standalone subsystem that operates in what you refer to as true redundancy. there’s another subsystem of radars and lidars, which also produces a comprehensive and coherent standalone model of the environment.

using these two models of the environment, we can reach what you also referred to as true redundancy, which means that for any decision that the vehicle is going to take, we would inspect it against two views of the environment, one produced by our computer vision system and the other one produced by the subsystem of radars and lidars.
now the linkage to the previous question is interesting in a sense that the same computer vision subsystem that propels our robotaxi or autonomous vehicle solution is the surround vision solution that we are taking to market as part of level 2+ segment.
and this fact alone is based on a strategic level of [technical difficulty] of technologies that were incubated and trickle them down into our driver assistance go-to-market, and the mapping is one other such example where we started with designing a crowd sourced mapping solution for our robotaxi, and we trickled it down all the way to driver assistance.
maybe the last differentiator that you mentioned is also a core differentiator here where our safety model for the vehicle, the safety concept for the vehicle is a model based -- a model that helps us describe very precisely what is the barrier between assertive driving and dangerous driving.
what sort of actions that we take may cause risks or inflict risks on other road users and what behavior would simply be more assertive and allow us to negotiate into traffic, and that barrier line -- that model that helps us clarify that very aligned trickles all the way down to our perception what should be protected more and what should be protected less.
what is safety critical and what is simply dealing with the comfort and convenience to the driver. this distinction is very strong and allows us to allocate resources into the problem in the -- in an intelligent way.
c.j. muse
that’s great. i think chris has a few questions on the adas robotaxi side, let me turn it over to you, chris.
chris mcnally
thanks, c.j. erez, and thanks so much for your participation. look, adas is still your bread and butter, right? so -- and an area where you continue to dominate market share. and i think you previously disclosed i think a $5 billion tam by 2024, and last year revenues were a little under $900 million. can you talk about the pace between now and ‘24, ‘25, can we see that revenue double or maybe something greater than that, simply because we see this big opportunity from level 2+ or level 2++ and anything you can add about the idea over unit penetration, just chips but also asp increases as we move up the stack?
erez dagan
okay. so there are two -- thanks for the question. it’s a very good one. there are two modes through which the revenue pile is about to increase in the driver assistance domain. the first mode is much increased fitment rates of lower end solutions, okay? we see that trend already. we already talked about it several times as well.
the regulations such as [indiscernible] gsr and many others mandates across the globe for trucks, et cetera, et cetera, are driving fitment rates faster that we -- than it was previously anticipated by the market, and that’s a substantial contribution to that trend that you were mentioning.
the second one is the second mode of more advanced features -- driver assistance features, level 2+ namely, and in that arena we do see a very rapid growth. i think that a lot -- that has a lot to do with the consumer awareness of automated driving -- autonomous driving technologies that also leaks into awareness through advanced driver assistance. so, we definitely see that on track as you denoted.
chris mcnally
and then maybe if we just drill down into this idea of level 2+, right, which is really evolving, a couple years ago, we were all thinking about level 3 and now it seems like level 2+ is something that’s going to make the oems a lot more money. how big could this be, and i mean, i don’t -- it doesn’t need to be specific? but could this end up being 20% of adas penetration in 2024 or 2025, 10 million-plus units or is it still going to take a little bit longer for it to evolve?

erez dagan
we predict also based on research that’s out there that we see north of 10 million units, ballpark of 12 million or 13 million units around that year. and yes, this segment of the market is really rushing very impressively forward. we can see that through our -- the market rfis and rfqs. it’s well-established basically.
chris mcnally
okay. and erez, do you think the current $5,000, $6,000, $7,000 for these sort of highway assist programs that are being charged to the customer, do you think that’s the right price, obviously, it’s not something that mobileye kind of has control over, but do you see that coming down over time because obviously that’s one of the inhibiting factors for level 2+ growth, it’s clear that consumers want?
erez dagan
so, i must admit i am not sure at what level these systems are priced to the end consumer and whether the figures you denoted are a level 2+ or a level 3 price. i am not tracking the price list. i have a full disclosure here.
but i can tell you about what we already shared about the way that we are seeing it evolving full -- not full, level 4 autonomy, not level 5, but level 4 autonomy is going to be introduced first, robotaxis and then a couple of years later, three years later, we expect the cost of these solutions to drop to several thousands of dollars cost, and that’s full autonomy that’s something that could drive in an urban scenario doorway to doorway kind of a personal show there.
the other data point that we also shared in the past is that the subsystem of the surround vision system is the affordable way to introduce level 2+ is visual centric, okay? cameras are giving you a very comprehensive model of environment combined with a map and these systems also in nature do not include expensive sensors.
and if you take into account the compute and the sensors, we are talking about hundreds of dollars of costs for these systems. so, again, pricing strategies and penetration strategies of oems, not for me to say, but i do expect that to have a -- if they -- if these are the prices currently charged, i expect that to go down as we go forward. i say, this is -- the economies of this solution is being tightened every day.
chris mcnally
great. and then one last one on adas and then i just want to talk about robotaxis in jerusalem. just on your recent adas, i mean, you essentially have such a large share. in q1, we noticed that you added a very major asian oem, would you be able to comment if this is sort of the one large japanese oem that you haven’t worked with in the past maybe up until now?
erez dagan
unfortunately, i cannot comment at this point, because of the dark period of it -- the quiet period. i would say that we see a lot of trust in the market has said it’s in the -- maybe the best way to look at it is that at 12 out of 15 top makers are using mobileye solutions. so we are there. we are going to continue our trust forward in the markets, and hopefully, we can sharing to see move those.
chris mcnally
great. just real quick before i send it back to c.j. so, look, robotaxi deployment is going to happen in jerusalem as the initial data commercial rollout i think in 2022. we have become a little bit numb to the idea of these data rollouts. could you just talk about what can we expect for an initial deployment in jerusalem for a commercial service? how robust will it be?
erez dagan
all right. so maybe it’s a good opportunity to also share about our -- what we have been doing in that space for the last 10 months or year or so. as i said, most notably, the acquisition of moovit and joining moovit to our force to reach that solution of full end-to-end service, we already have our robotaxi development fleets and hooked on the moovit service application.

again, not public -- not publicly available but is in development step and we can close the link for a full service on the technical level. on the maturity of these solutions and the time to get to market, we are on track with plans as stated in the past, no setback whatsoever.
we are -- in terms of what you are going to experience, again, back to your question, simply calling out for a vehicle out of a multimodal -- application of multimodal options of transport, you can choose an autonomous vehicle as one of them, hop on the car, get a notice when you get off the car and get a notice when the transaction is complete.
within those car, there is access to a call center in the back. there is teleoperation center that has also the way to look into the cabin, into the surrounding of the vehicle in case anything is required for that purpose. that’s an exciting thing to share it’s on track and we are looking forward to launch it in israel.
chris mcnally
that’s fantastic. c.j. i set it back to you. i could talk about ev all day, but why don’t you -- get focus back on the semi side.
c.j. muse
sure. sure. so, yeah, i really wanted to i guess focus a bit more on your partnership now as part of intel. and so as you think about creating a full self-driving system and providing a full solution, can you kind of speak to both hardware and software? and what intel brings to the table to mobileye that really is a accretive to the work that you guys are doing?
erez dagan
sure. so one important almost immediate value that we were able to get as part of the acquisition is a very strong team writing software and compilers that helped us open up the iq files to be a compute platform. that was a very impressive and very quick contribution that we got there.
there is a lot of contributions in the area of -- at the system level whenever it comes out from the so secret system level. we are getting a lot of experience by experienced developers and development work forces in intel.
of course, understand strategic steering, we are also consulting our mothership in that sense, and i think -- and capital as we already also executed on the moovit deal to help us secure the path forward.
c.j. muse
that’s great. i guess digging a little bit deeper based on the analyst day, i guess, 10 months ago, it sounded like intel working on other parts of the portfolio, lidar sensors, imaging radar, silicon photonics. so, i guess, as you as you think about all the work being done there maybe you could kind of walk through what’s most exciting and how do you see insourcing versus outsourcing, looking out to -- from the current adas part of the world to through level 5?
erez dagan
indeed. we did have a launch of an activity inside of intel under ic as a unit. we are working on very interesting both on the rf technology and the silicon photonics that should yield and we are seeing already some first versions, very impressive radar and lidar solutions.
these are, i think, that to be a bit more specific in radars, we are talking about high angular resolution radars, which is the quest in that space, increasing the angular resolution while maintaining both power and compute within reasonable ranges.
and with lidar, the undertaking is often coherent lidar, which has on top of the depth estimation, the estimation of the doppler or the speed of the object. so both are on track and both are yielding very exciting results.
c.j. muse
that’s great. we have a question from the audience and the focus is around 5g, eventually 6g. how will that change the way image sensors operate seeing sync with ai?
erez dagan
so in our space i would not expect or assume that that’s -- and my take on it that it won’t take ai compute -- safety critical ai compute from the edge, okay? we will not be able to count on cellular communication to take -- to carry out safety critical calculations or inferences.

the proliferation of network solutions would allow, of course, a maybe faster, maybe cheaper and maybe facilitate better the transfer of data for some offline processing, okay? but it will not impact the real-time processing required to be carried out on the edge.
c.j. muse
i guess a final semiconductor question and i am not sure what you can share and what you can’t share. but as you think about your rollout of iq5 and iq6, can you help us understand what kind of technology you are bringing in terms of what’s additive, what are the new features, as well as how do we think about that greater content and the contributions to your opportunity per vehicle?
erez dagan
sure. so in iq5 we started the journey of co-hosting on our chip, which means that allows to -- allows for scalability of our solutions across multiple vehicle levels -- vehicle platforms. it allows for ability to save additional compute units around the iq because you can host some peripheral software on iq itself. it allows co-hosting of this added value, synergetic value such as driver and monitoring systems that we also host from a third-party and gives us the flexibility for this.
the market is continuously looking for optimizing the transactions, as well as the products. and that gives us another degree of flexibility when it comes to more creative transactions and creative -- creating models of integration in the car.
when we move to iq6 of course we are going to preserve all of these and enhance all of these, the programmability for -- the programmability of iq5 will be continued and enforced in iq6. the division with regards to iq6 was shared in last time at cs. it will be a continuation of the iq5, maintaining same trends and fortifying our position as we go forward.
c.j. muse
that’s great. i was hoping to now move over to the competitive landscape and i know both chris and i have questions here. just the first one is, i think, you have mentioned recently or intel mobileye has that covid could have a positive impact and that oems are more likely to go to more off-the-shelf technology relevant -- rather than developing their own chips. so can you provide perhaps more color around this line of thinking?
erez dagan
sure. so when you look at oems and the amount of resources invested in customizing the product on each product launch, it’s a very large amount of resources. it requires reintegration and revalidation of products that could otherwise been used more as is.
and this customization, validations and integration are our across the end of work and could be, again, we are yet to see, we are just in the beginning of the effects of the covid, but it could be that these resources may be spared in favor of adopting less customized and more already validated and battle tested solutions.
c.j. muse
and then how do you think of the overall competitive landscape and i would love to hear in particular the recently announced partnership between nvidia and mercedes benz?
erez dagan
i will talk about the market and its structure and what it could mean for, in terms of how easy it is to penetrate into the market. as i started saying already, the driver assistance computer vision market is no longer a young market. the set of solutions in that space are very rich.
and in order to launch a camera on a windshield of a vehicle, you need to have a very comprehensive set of tools and very well tested because of the liabilities of breaking the car based on the camera, et cetera.
so saying, it’s not like 2004 where you detected two-lane marks and you had your camera on the windshield. today it’s a full suite of road detection, vehicles detection, pedestrian direction, cyclists and the list goes on, and traffic signs and whatnot. so the solutions today even at the entry level are becoming more and more demanding, okay?

on the other end, as i said, the -- there is strong price pressures on these very low-end segments because of the volumes that the oems wants to introduce or sometimes required to introduce these solutions into because of regulation. so -- and the third element is, of course, the fact that revenue in this market is almost evenly dispersed across the oems.
so taking the three together and doing the calculation it means that, to compensate for the undertaking of creating a camera that is launched on a commercial product, you need to win a lot of volume of business from multiple oems in the market and this is kind of a structural state of the market today where it is. so we see a lot of energy and a lot of investment being poured into it.
it’s -- there is a very attractive tam on the other side of it as we also denoted today. the tam that -- the tam rise between us and the rest of the research in this industry predict is calling for investments in grid. and as we see so far we are able to well preserve our position in the market with very strong technical differentiation.
we continuously reinvent what adas is. we continuously stretch that envelope also through discussions with our oem partners and through bodies like euro ncap and advising on regulation that -- on value that can be added to these cameras and we are looking strong with our market share and riding very well that wave of increased fitment rates.
chris mcnally
erez, if i could just jump on to c.j.’s question. specifically, one of the ones that we have a discussion across teams is obviously daimler and nvidia, because that’s a higher end solution. do you see -- one of the great things that you offer is the idea of live mapping through rem. so i would be curious if, one, you see a competitive alternative to rem map that would be out there. and then the second is maybe you just give a quick update on the timeline of rolling out rem, so that we could see sort of those enhanced products?
erez dagan
so as for alternatives to rem, the question you are asking is whether there is another source of this size of driver assistance cameras deployed out there. and as far as you know the answer is no.
so in terms of sources of data for these crowd source fleets, we have a quite well differentiated asset there. and there are other solutions of hd mapping, but you would not -- i would not refer to these as crowd sourced or real-time refreshed hd mapping. so the first answer in its own category, there is no such alternative that i am aware of yet.
as for the introduction of rem-based vehicles, there was already one launch of a recent vehicle which i think it was well-published, nissan pro pilots in japan and we are expecting, as we said, launches later this year in europe, a significant launch.
c.j. muse
i guess, just to follow up. you talked about 12 of the top 15 oem wins. how do you think about your obvious leadership dominance level 2 -- 2+, the adas world? how does that translate to what you expect your market position will be when we get to level 5?
erez dagan
so these are two different journeys and it’s very important not to mix them. there is a lot of people that did use that -- on the other direction that any company that works on a prototype robotaxi vehicle and shows some hands-off driving is geared to deal with the undertaking of adas, which is a different problem. it’s kind of, if i can fly planes let’s make cars, it’s not really mistaking. the economies in the driver assistance, the power constraints of all sorts are completely different.
so, again, i just wanted to first disambiguate the things. our strength in driver assistance is one thing and our strength in autonomous driving, while feeding off of our computer vision technology has a lot more to it.

the way that we see, the fact that we are working under these very strict economies of adas products, while we are developing our computer vision solutions and since this same computer vision backbone is propelling our robotaxi, we expect to be well ahead of the market curve in terms of the economies of a self-driving system, because we are building it from building blocks that are technically and economically forged in the driver assistance space.
c.j. muse
that’s very helpful. so, we only have about three minutes left. so i guess with that limited time, what -- as you look out over the next 12 months, what are you most excited about, and perhaps, that could be our concluding takeaway today?
erez dagan
i can only sure think that i was excited about before the quite period. that’s kind of delayed that. but i am looking forward to the very -- we had very, very interesting and very important achievements as far as the regulatory, the very important regulatory campaign that is undergoing to make rss the backbone of the framework, sorry, according to which robotaxis are made a reality. the ieee body that we have initiated is one important example and we will conclude it to make this a reality multiple content.
c.j. muse
great. we got maybe a minute or two. do you have any final question?
chris mcnally
yeah. i mean, it’s a tough one, but real quick. regulation, do you see it has any issue right now and at least in your initial rollout in jerusalem? and obviously, it’s a longer question, but for now do you think regulation is supportive?
erez dagan
so regulation, we have seen very interesting and important movements both in europe and germany, as well as in jerusalem. these are still focusing on at testing fleets as first steps, but the discussion is now very well awake.
everyone understands that in order to make a computer drive along -- on the road with humans, there needs to be some more computer readable framework of what it means to drive carefully and i think that that’s an important achievement that we have had going on multiple -- as i said, multiple circles with intel circles.
c.j. muse
all right. tony, on behalf of evercore isi and chris and me in particular, thank you for your time. really appreciate it and learned a lot. so, thank you.
tony balow
thanks so much.
erez dagan
thank you.
chris mcnally
thanks, guys.
c.j. muse
thanks.